{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined TF-IDF and BoW Features:\n",
      "Accuracy: 92.11%\n",
      "F1 Score: 92.09%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.93      0.89      0.91       313\n",
      "      netral       0.89      0.98      0.93       291\n",
      "     positif       0.96      0.90      0.92       296\n",
      "\n",
      "    accuracy                           0.92       900\n",
      "   macro avg       0.92      0.92      0.92       900\n",
      "weighted avg       0.92      0.92      0.92       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[279  22  12]\n",
      " [  6 285   0]\n",
      " [ 16  15 265]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def prepare_datasets(corpus, labels, test_data_proportion=0.3, random_state=42):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels,\n",
    "                                                        test_size=test_data_proportion,\n",
    "                                                        random_state=random_state)\n",
    "    return train_X, test_X, train_Y, test_Y\n",
    "    \n",
    "def tfidf_extractor(corpus, ngram_range=(1,2)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                norm='l2',\n",
    "                                smooth_idf=True,\n",
    "                                use_idf=True,\n",
    "                                ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "def bow_extractor(corpus, ngram_range=(1,1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "df = pd.read_csv('sentiment_otomatis_3000.csv')\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = prepare_datasets(df['content'], df['sentimen'], test_data_proportion=0.3)\n",
    "\n",
    "# Convert text labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ensure the lengths match after splitting\n",
    "y_train_encoded = y_train_encoded[:len(x_train)]\n",
    "y_test_encoded = y_test_encoded[:len(x_test)]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(x_train)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "# Bag of Words (BoW) features\n",
    "count_vectorizer, count_train_features = bow_extractor(x_train)\n",
    "count_test_features = count_vectorizer.transform(x_test)\n",
    "\n",
    "# Combine TF-IDF and BoW features\n",
    "combined_train_features = hstack([tfidf_train_features, count_train_features])\n",
    "combined_test_features = hstack([tfidf_test_features, count_test_features])\n",
    "\n",
    "# Define function to train and evaluate Logistic Regression classifier\n",
    "def train_and_evaluate(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    # Train the classifier\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(test_labels, predictions, target_names=label_encoder.classes_)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    matrix = confusion_matrix(test_labels, predictions)\n",
    "    \n",
    "    return accuracy * 100, f1 * 100, report, matrix\n",
    "\n",
    "# Train and evaluate on combined features\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "combined_accuracy, combined_f1, combined_report, combined_matrix = train_and_evaluate(lr_model, combined_train_features, y_train_encoded, combined_test_features, y_test_encoded)\n",
    "\n",
    "print(\"Combined TF-IDF and BoW Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(combined_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(combined_f1))\n",
    "print(\"Classification Report:\\n\", combined_report)\n",
    "print(\"Confusion Matrix:\\n\", combined_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Probabilities (in percentages): {'negatif': '15.90%', 'netral': '82.89%', 'positif': '1.20%'}\n"
     ]
    }
   ],
   "source": [
    "# Function to predict sentiment probabilities for new text\n",
    "def predict_sentiment(text):\n",
    "    # Transform the text using both vectorizers\n",
    "    tfidf_features = tfidf_vectorizer.transform([text])\n",
    "    bow_features = count_vectorizer.transform([text])\n",
    "    \n",
    "    # Combine features\n",
    "    combined_features = hstack([tfidf_features, bow_features])\n",
    "    \n",
    "    # Predict probabilities\n",
    "    probabilities = lr_model.predict_proba(combined_features)[0]\n",
    "    \n",
    "    # Convert probabilities to percentages and map to sentiment labels\n",
    "    sentiment_probs = {label: f\"{prob * 100:.2f}%\" for label, prob in zip(label_encoder.classes_, probabilities)}\n",
    "    \n",
    "    return sentiment_probs\n",
    "\n",
    "# Example usage\n",
    "new_text = \"Dalam Kejadian pembunuhan pada hari ini banyak sekali bukti dan korban yang membuat kesedihan dari banyak orang\"\n",
    "sentiment_probabilities = predict_sentiment(new_text)\n",
    "print(\"Sentiment Probabilities (in percentages):\", sentiment_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Dictionary to store model and vectorizer\n",
    "model_data = {\n",
    "    'model': lr_model,  # your trained Logistic Regression model\n",
    "    'tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'count_vectorizer': count_vectorizer,\n",
    "    'label_encoder': label_encoder\n",
    "}\n",
    "\n",
    "# Save the model data to a file\n",
    "joblib.dump(model_data, 'model_sentimen_lr.pkl')\n",
    "\n",
    "# Function to predict sentiment probabilities for new text using the saved model\n",
    "def predict_sentiment(text, model_path='model_sentimen_lr.pkl'):\n",
    "    # Load the model data\n",
    "    loaded_model_data = joblib.load(model_path)\n",
    "    model = loaded_model_data['model']\n",
    "    tfidf_vectorizer = loaded_model_data['tfidf_vectorizer']\n",
    "    count_vectorizer = loaded_model_data['count_vectorizer']\n",
    "    label_encoder = loaded_model_data['label_encoder']\n",
    "    \n",
    "    # Transform the text using both vectorizers\n",
    "    tfidf_features = tfidf_vectorizer.transform([text])\n",
    "    bow_features = count_vectorizer.transform([text])\n",
    "    \n",
    "    # Combine features\n",
    "    combined_features = hstack([tfidf_features, bow_features])\n",
    "    \n",
    "    # Predict probabilities\n",
    "    probabilities = model.predict_proba(combined_features)[0]\n",
    "    \n",
    "    # Convert probabilities to percentages and map to sentiment labels\n",
    "    sentiment_probs = {label: f\"{prob * 100:.2f}%\" for label, prob in zip(label_encoder.classes_, probabilities)}\n",
    "    \n",
    "    return sentiment_probs\n",
    "\n",
    "# Example usage\n",
    "new_text = \"Dalam Kejadian pembunuhan pada hari ini banyak sekali bukti dan korban yang membuat kesedihan dari banyak orang\"\n",
    "sentiment_probabilities = predict_sentiment(new_text)\n",
    "print(\"Sentiment Probabilities (in percentages):\", sentiment_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Function to predict sentiment probabilities for new text data using the saved model\n",
    "def predict_sentiment_probabilities(new_data, model_path='model_sentimen_lr.pkl'):\n",
    "    # Load the model data\n",
    "    loaded_model_data = joblib.load(model_path)\n",
    "    loaded_model = loaded_model_data['model']\n",
    "    loaded_tfidf_vectorizer = loaded_model_data['tfidf_vectorizer']\n",
    "    loaded_count_vectorizer = loaded_model_data['count_vectorizer']\n",
    "    loaded_label_encoder = loaded_model_data['label_encoder']\n",
    "    \n",
    "    # Transform the new data using both vectorizers\n",
    "    tfidf_features = loaded_tfidf_vectorizer.transform(new_data)\n",
    "    bow_features = loaded_count_vectorizer.transform(new_data)\n",
    "    \n",
    "    # Combine features\n",
    "    combined_features = hstack([tfidf_features, bow_features])\n",
    "    \n",
    "    # Predict probabilities for each sentiment class using the loaded model\n",
    "    probabilities = loaded_model.predict_proba(combined_features)\n",
    "    \n",
    "    # Print the predicted probabilities for each text\n",
    "    for text, prob in zip(new_data, probabilities):\n",
    "        sentiment_probs = {label: f\"{p * 100:.2f}%\" for label, p in zip(loaded_label_encoder.classes_, prob)}\n",
    "        print(f\"Text: '{text}' -> Sentiment Probabilities: {sentiment_probs}\")\n",
    "\n",
    "# Example usage\n",
    "new_data = [\n",
    "    \"Dalam Kejadian pembunuhan pada hari ini banyak sekali bukti dan korban yang membuat kesedihan dari banyak orang\",\n",
    "    \"Hari ini sangat menyenangkan dan penuh kegembiraan\",\n",
    "    \"Saya merasa netral tentang kejadian ini\"\n",
    "]\n",
    "\n",
    "predict_sentiment_probabilities(new_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
