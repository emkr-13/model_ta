{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus, ngram_range=(1,2)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                norm='l2',\n",
    "                                smooth_idf=True,\n",
    "                                use_idf=True,\n",
    "                                ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(corpus, labels, test_data_proportion=0.3, random_state=42):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels,\n",
    "                                                        test_size=test_data_proportion,\n",
    "                                                        random_state=random_state)\n",
    "    return train_X, test_X, train_Y, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>presiden joko widodo jokowi korupsi kejahatan ...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wali kota depok mohammad idris menanggapi nyin...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>komika lampung aulia rakhman viral media sosia...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unggahan berisi daftar afiliasi politik pegawa...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>menko polhukam mahfud md merespons pernyataan ...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>calon wakil presiden cawapres nomor urut 1 muh...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>capres ganjar pranowo sikap presiden joko wido...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>menteri investasi bahlil lahadalia bicara isu ...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>massa buruh buka suara memblokade tol cipulara...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>raut kecewa terpancar wajah ridwan nasution 43...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentimen\n",
       "0  presiden joko widodo jokowi korupsi kejahatan ...  negatif\n",
       "1  wali kota depok mohammad idris menanggapi nyin...  negatif\n",
       "2  komika lampung aulia rakhman viral media sosia...  negatif\n",
       "3  unggahan berisi daftar afiliasi politik pegawa...  negatif\n",
       "4  menko polhukam mahfud md merespons pernyataan ...  negatif\n",
       "5  calon wakil presiden cawapres nomor urut 1 muh...  negatif\n",
       "6  capres ganjar pranowo sikap presiden joko wido...  negatif\n",
       "7  menteri investasi bahlil lahadalia bicara isu ...  negatif\n",
       "8  massa buruh buka suara memblokade tol cipulara...  negatif\n",
       "9  raut kecewa terpancar wajah ridwan nasution 43...  negatif"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sentiment_pemilu_otomatis_1500.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = prepare_datasets(df['content'], df['sentimen'], test_data_proportion=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ensure the lengths match after splitting\n",
    "y_train_encoded = y_train_encoded[:len(x_train)]\n",
    "y_test_encoded = y_test_encoded[:len(x_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(x_train)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words (BoW) features\n",
    "count_vectorizer, count_train_features = tfidf_extractor(x_train, ngram_range=(1, 1))  # Unigram features\n",
    "count_test_features = count_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF and BoW features\n",
    "combined_train_features = hstack([tfidf_train_features, count_train_features])\n",
    "combined_test_features = hstack([tfidf_test_features, count_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train and evaluate Naive Bayes classifier\n",
    "def train_and_evaluate(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    # Train the classifier\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined TF-IDF and BoW Accuracy: 90.89%\n",
      "Combined TF-IDF and BoW F1 Score: 90.86%\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM\n",
    "model_svm_parameter =  SVC(C=10, gamma=0.1, kernel='sigmoid')\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate on Combined TF-IDF and BoW features\n",
    "combined_accuracy, combined_f1 = train_and_evaluate(model_svm_parameter , combined_train_features, y_train_encoded, combined_test_features, y_test_encoded)\n",
    "\n",
    "\n",
    "print(\"Combined TF-IDF and BoW Accuracy: {:.2f}%\".format(combined_accuracy * 100))\n",
    "print(\"Combined TF-IDF and BoW F1 Score: {:.2f}%\".format(combined_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_sentimen_svm.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "# # Dictionary to store model and vectorizer\n",
    "# model_data = {\n",
    "#     'model': model_svm_parameter,  # your trained Logistic Regression model\n",
    "#     'tfidf_vectorizer': tfidf_vectorizer,\n",
    "#     'count_vectorizer': count_vectorizer,\n",
    "#     'label_encoder': label_encoder\n",
    "# }\n",
    "\n",
    "# # Save the model data to a file\n",
    "# joblib.dump(model_data, 'model_sentimen_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model data\n",
    "loaded_model_data = joblib.load('model_sentimen_svm.pkl')\n",
    "\n",
    "# Extract the components\n",
    "lr_model = loaded_model_data['model']\n",
    "tfidf_vectorizer = loaded_model_data['tfidf_vectorizer']\n",
    "count_vectorizer = loaded_model_data['count_vectorizer']\n",
    "label_encoder = loaded_model_data['label_encoder']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Sedang uji coba kritik -> Sentiment: negatif\n"
     ]
    }
   ],
   "source": [
    "def preprocess_new_data(new_data):\n",
    "    # Transform the new data using the loaded vectorizers\n",
    "    tfidf_features = tfidf_vectorizer.transform(new_data)\n",
    "    count_features = count_vectorizer.transform(new_data)\n",
    "    \n",
    "    # Combine the features\n",
    "    combined_features = hstack([tfidf_features, count_features])\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "def predict_sentiment(new_data):\n",
    "    # Preprocess the new data\n",
    "    combined_features = preprocess_new_data(new_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = lr_model.predict(combined_features)\n",
    "    \n",
    "    # Convert numerical labels back to original text labels\n",
    "    text_predictions = label_encoder.inverse_transform(predictions)\n",
    "    \n",
    "    return text_predictions\n",
    "\n",
    "# Example new data\n",
    "new_texts = [\"Sedang uji coba kritik\"]\n",
    "\n",
    "# Get predictions\n",
    "predictions = predict_sentiment(new_texts)\n",
    "\n",
    "# Print predictions\n",
    "for text, prediction in zip(new_texts, predictions):\n",
    "    print(f\"Text: {text} -> Sentiment: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
