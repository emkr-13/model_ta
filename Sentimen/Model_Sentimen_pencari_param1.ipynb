{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Rekomondasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persiapaan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(corpus, labels, test_data_proportion=0.3, random_state=42):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels,\n",
    "                                                        test_size=test_data_proportion,\n",
    "                                                        random_state=random_state)\n",
    "    return train_X, test_X, train_Y, test_Y\n",
    "    \n",
    "def tfidf_extractor(corpus, ngram_range=(1,2)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                norm='l2',\n",
    "                                smooth_idf=True,\n",
    "                                use_idf=True,\n",
    "                                ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "def bow_extractor(corpus, ngram_range=(1,1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ivan 31 pedagang sayur pasar kemiri muka depok...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pasukan militer israel operasi serangan tepi b...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suami berinisial 32 tega kekerasan rumah tangg...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menghambat pasokan bantuan penduduk gaza kejah...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>praktik dunia kerap ditemukan perusahaan menah...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cawapres nomor urut 1 muhaimin iskandar cak im...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ketum pdi perjuangan pdip megawati soekarnoput...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pengguna lrt jabodebek mengeluhkan waktu tungg...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heboh media sosial isu anggota bem universitas...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobil dipamerkan mal semarang jawa tengah hila...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentimen\n",
       "0  ivan 31 pedagang sayur pasar kemiri muka depok...  negatif\n",
       "1  pasukan militer israel operasi serangan tepi b...  negatif\n",
       "2  suami berinisial 32 tega kekerasan rumah tangg...  negatif\n",
       "3  menghambat pasokan bantuan penduduk gaza kejah...  negatif\n",
       "4  praktik dunia kerap ditemukan perusahaan menah...  negatif\n",
       "5  cawapres nomor urut 1 muhaimin iskandar cak im...  negatif\n",
       "6  ketum pdi perjuangan pdip megawati soekarnoput...  negatif\n",
       "7  pengguna lrt jabodebek mengeluhkan waktu tungg...  negatif\n",
       "8  heboh media sosial isu anggota bem universitas...  negatif\n",
       "9  mobil dipamerkan mal semarang jawa tengah hila...  negatif"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sentiment_otomatis_3000.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = prepare_datasets(df['content'], df['sentimen'], test_data_proportion=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ensure the lengths match after splitting\n",
    "y_train_encoded = y_train_encoded[:len(x_train)]\n",
    "y_test_encoded = y_test_encoded[:len(x_test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(x_train)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "# Bag of Words (BoW) features\n",
    "count_vectorizer, count_train_features = bow_extractor(x_train)\n",
    "count_test_features = count_vectorizer.transform(x_test)\n",
    "\n",
    "# Combine TF-IDF and BoW features\n",
    "combined_train_features = hstack([tfidf_train_features, count_train_features])\n",
    "combined_test_features = hstack([tfidf_test_features, count_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah fitur TF-IDF: 136955\n",
      "Jumlah fitur Bag of Words: 18458\n",
      "Jumlah fitur gabungan: 155413\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Features\n",
    "print(\"Jumlah fitur TF-IDF:\", tfidf_train_features.shape[1])\n",
    "\n",
    "# Bag of Words (BoW) Features\n",
    "print(\"Jumlah fitur Bag of Words:\", count_train_features.shape[1])\n",
    "\n",
    "# Combined Features\n",
    "print(\"Jumlah fitur gabungan:\", combined_train_features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Naiye Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to train and evaluate Naive Bayes classifier\n",
    "def train_and_evaluate(classifier, train_features, train_labels, test_features, test_labels):\n",
    "    # Train the classifier\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(test_labels, predictions, target_names=label_encoder.classes_)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    matrix = confusion_matrix(test_labels, predictions)\n",
    "    \n",
    "    return accuracy * 100, f1 * 100, report, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(matrix, labels):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanpa Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "model_naiye_tanpa_parameter = MultinomialNB()\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(model_naiye_tanpa_parameter , count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 86.56%\n",
      "F1 Score: 86.42%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.87      0.86      0.87       313\n",
      "      netral       0.93      0.76      0.84       291\n",
      "     positif       0.81      0.97      0.88       296\n",
      "\n",
      "    accuracy                           0.87       900\n",
      "   macro avg       0.87      0.87      0.86       900\n",
      "weighted avg       0.87      0.87      0.86       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[270  13  30]\n",
      " [ 33 222  36]\n",
      " [  6   3 287]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning GridCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.1\n",
      "Best alpha: MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(model_naiye_tanpa_parameter, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(count_train_features, y_train_encoded)\n",
    "\n",
    "# Get the best parameter\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best alpha:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pakai Paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "model_naiye_parameter = MultinomialNB(alpha=0.1)\n",
    "\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(model_naiye_parameter , count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 87.89%\n",
      "F1 Score: 87.80%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.87      0.87      0.87       313\n",
      "      netral       0.93      0.80      0.86       291\n",
      "     positif       0.85      0.96      0.90       296\n",
      "\n",
      "    accuracy                           0.88       900\n",
      "   macro avg       0.88      0.88      0.88       900\n",
      "weighted avg       0.88      0.88      0.88       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[273  14  26]\n",
      " [ 33 233  25]\n",
      " [  8   3 285]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanpa Paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "svm_tanpa_parameter = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(svm_tanpa_parameter , count_train_features, y_train_encoded, count_test_features, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 90.22%\n",
      "F1 Score: 90.19%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.89      0.87      0.88       313\n",
      "      netral       0.86      0.98      0.92       291\n",
      "     positif       0.96      0.86      0.91       296\n",
      "\n",
      "    accuracy                           0.90       900\n",
      "   macro avg       0.91      0.90      0.90       900\n",
      "weighted avg       0.91      0.90      0.90       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[272  30  11]\n",
      " [  7 284   0]\n",
      " [ 25  15 256]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Best Parameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# # Define the parameter grid\n",
    "# param_grid_svm = {'C': [0.1, 1, 10],\n",
    "#                   'gamma': [0.1, 0.01, 0.001],\n",
    "#                   'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search_svm = GridSearchCV(svm_tanpa_parameter, param_grid_svm, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search_svm.fit(count_train_features, y_train_encoded)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params_svm = grid_search_svm.best_params_\n",
    "# print(\"Best Parameters:\", best_params_svm)\n",
    "\n",
    "# # Get the best model\n",
    "# best_model_svm = grid_search_svm.best_estimator_\n",
    "# print(\"Best Parameters:\", best_params_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pakai Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "svm_parameter = SVC(C=10, gamma=0.001, kernel='rbf')\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(svm_parameter , count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 90.44%\n",
      "F1 Score: 90.40%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.92      0.87      0.89       313\n",
      "      netral       0.86      0.99      0.92       291\n",
      "     positif       0.95      0.86      0.90       296\n",
      "\n",
      "    accuracy                           0.90       900\n",
      "   macro avg       0.91      0.91      0.90       900\n",
      "weighted avg       0.91      0.90      0.90       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[272  27  14]\n",
      " [  4 287   0]\n",
      " [ 21  20 255]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanpa Paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "lr_tanpa_parameter = LogisticRegression(random_state=42,max_iter=1000)\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(lr_tanpa_parameter , count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 92.22%\n",
      "F1 Score: 92.20%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.93      0.89      0.91       313\n",
      "      netral       0.89      0.98      0.93       291\n",
      "     positif       0.96      0.90      0.92       296\n",
      "\n",
      "    accuracy                           0.92       900\n",
      "   macro avg       0.92      0.92      0.92       900\n",
      "weighted avg       0.92      0.92      0.92       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[279  22  12]\n",
      " [  5 286   0]\n",
      " [ 16  15 265]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter grid\n",
    "# param_grid_lr = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "#                   'max_iter': [1000]\n",
    "#                  }\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search_lr = GridSearchCV(lr_tanpa_parameter, param_grid_lr, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search_lr.fit(count_train_features, y_train_encoded)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params_lr = grid_search_lr.best_params_\n",
    "# print(\"Best Parameters:\", best_params_lr)\n",
    "\n",
    "# # Get the best model\n",
    "# best_model_lr = grid_search_lr.best_estimator_\n",
    "# print(\"Best Parameters:\", best_params_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "lr_parameter =  LogisticRegression(C=0.1,max_iter=1000)\n",
    "\n",
    "## Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(lr_parameter , count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 92.44%\n",
      "F1 Score: 92.43%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.95      0.88      0.92       313\n",
      "      netral       0.87      0.99      0.93       291\n",
      "     positif       0.96      0.91      0.93       296\n",
      "\n",
      "    accuracy                           0.92       900\n",
      "   macro avg       0.93      0.93      0.92       900\n",
      "weighted avg       0.93      0.92      0.92       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[275  27  11]\n",
      " [  2 289   0]\n",
      " [ 11  17 268]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanpa Paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "rfc_tanpa_parameter = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(rfc_tanpa_parameter, count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 90.11%\n",
      "F1 Score: 89.99%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.95      0.81      0.87       313\n",
      "      netral       0.86      0.99      0.92       291\n",
      "     positif       0.90      0.92      0.91       296\n",
      "\n",
      "    accuracy                           0.90       900\n",
      "   macro avg       0.90      0.90      0.90       900\n",
      "weighted avg       0.91      0.90      0.90       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[252  30  31]\n",
      " [  3 288   0]\n",
      " [  9  16 271]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the parameter grid\n",
    "# param_grid_rfc = {'n_estimators': [50, 100, 200],\n",
    "#                   'max_depth': [None, 10, 20, 30],\n",
    "#                   'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search_rfc = GridSearchCV(rfc_tanpa_parameter, param_grid_rfc, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search_rfc.fit(count_train_features, y_train_encoded)\n",
    "\n",
    "# # Get the best parameters\n",
    "# best_params_rfc = grid_search_rfc.best_params_\n",
    "# print(\"Best Parameters:\", best_params_rfc)\n",
    "\n",
    "# # Get the best model\n",
    "# best_model_rfc = grid_search_rfc.best_estimator_\n",
    "# print(\"Best Parameters:\", best_model_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier\n",
    "rfc_parameter = RandomForestClassifier(min_samples_split=2,n_estimators=100)\n",
    "\n",
    "# Train and evaluate on Bag of Words (BoW) features\n",
    "bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(rfc_tanpa_parameter, count_train_features, y_train_encoded, count_test_features, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 90.11%\n",
      "F1 Score: 89.99%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.95      0.81      0.87       313\n",
      "      netral       0.86      0.99      0.92       291\n",
      "     positif       0.90      0.92      0.91       296\n",
      "\n",
      "    accuracy                           0.90       900\n",
      "   macro avg       0.90      0.90      0.90       900\n",
      "weighted avg       0.91      0.90      0.90       900\n",
      "\n",
      "Confusion Matrix:\n",
      " [[252  30  31]\n",
      " [  3 288   0]\n",
      " [  9  16 271]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag of Words (BoW) Features:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "print(\"Classification Report:\\n\", bow_report)\n",
    "print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil model terbaik dari hasil tuning\n",
    "best_model_naive_bayes = model_naiye_parameter\n",
    "best_model_svm = svm_parameter\n",
    "best_model_random_forest = rfc_parameter\n",
    "best_model_logistic_regression = lr_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Gabungin 4 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Membuat model ensemble\n",
    "# ensemble_model_4 = VotingClassifier(estimators=[\n",
    "#     ('naive_bayes', best_model_naive_bayes),\n",
    "#     ('svm', best_model_svm),\n",
    "#     ('random_forest', best_model_random_forest),\n",
    "#     ('logistic_regression', best_model_logistic_regression)\n",
    "# ], voting='hard')\n",
    "\n",
    "# # Train and evaluate on Bag of Words (BoW) features\n",
    "# bow_accuracy, bow_f1,bow_report,bow_matrix = train_and_evaluate(ensemble_model_4, count_train_features, y_train_encoded, count_test_features, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) Features:\n",
      "Accuracy: 94.32%\n",
      "F1 Score: 94.31%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.95      0.91      0.93       272\n",
      "      netral       0.91      0.99      0.95       280\n",
      "     positif       0.97      0.93      0.95       276\n",
      "\n",
      "    accuracy                           0.94       828\n",
      "   macro avg       0.94      0.94      0.94       828\n",
      "weighted avg       0.94      0.94      0.94       828\n",
      "\n",
      "Confusion Matrix:\n",
      " [[247  19   6]\n",
      " [  3 276   1]\n",
      " [ 11   7 258]]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Bag of Words (BoW) Features:\")\n",
    "# print(\"Accuracy: {:.2f}%\".format(bow_accuracy))\n",
    "# print(\"F1 Score: {:.2f}%\".format(bow_f1))\n",
    "# print(\"Classification Report:\\n\", bow_report)\n",
    "# print(\"Confusion Matrix:\\n\", bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 dengan Akurasi Terbaik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Dengan Nilai Akurasi Terbaik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# # Dictionary to store model and vectorizer\n",
    "# model_data = {\n",
    "#     'model': ensemble_model_4,  # your trained Logistic Regression model\n",
    "#     'vectorizer': count_vectorizer,\n",
    "#     'label_encoder': label_encoder\n",
    "# }\n",
    "\n",
    "# # Save the model data to a file\n",
    "# joblib.dump(model_data, 'gabungan_4model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'bogor keluarga fw 22 perempuan dibunuh pacarnya ra alias alung 20 bogor pelaku dihukum berat ayah korban iwan irawan terima alung dihukum 15 tahun penjara sesuai pasal 338 kuhp pembunuhan iwan berharap alung dihukum seberat beratnya penjara seumur hidup baca wanita dibunuh pacarnya bogor mulutnya dibekap hidungnya digigit kepolisian hukum seberat beratnya seadil adilnya nyawa anak keberatan 15 tahun harapannya seumur hidup iwan ditemui mapolresta bogor kota selasa 5 12 2023 iwan menyangka kekasih anaknya pelaku pembunuh darah dagingnya hubungan asmara terjalin tahun setahun kenal dianggap anak main rumah iwan timbal baliknya bohong anak meninggal jatuh motor dibunuh sambung baca bekap pacar tewas bogor pelaku niat membunuhsejak peristiwa tragis iwan keluarga tersangka iktikad pemakaman anaknya keluarga tersangka keluarga tersangka iktikad baiknya ga komunikasinya iwan nyawa aja pertemuan pemakaman sambung' -> Predicted Sentiment: 'negatif'\n",
      "Text: 'calon presiden bacapres ganjar pranowo mengawali aktivitasnya berlari seputaran kota bandung jawa barat pria berambut putih menyusuri gang gang pemukiman warga' -> Predicted Sentiment: 'netral'\n"
     ]
    }
   ],
   "source": [
    "# # Later, to load the model data from the file\n",
    "# loaded_model_data = joblib.load('gabungan_4model.pkl')\n",
    "\n",
    "# # Extract model and vectorizer from loaded data\n",
    "# loaded_model = loaded_model_data['model']\n",
    "# loaded_vectorizer = loaded_model_data['vectorizer']\n",
    "# new_data = [\"bogor keluarga fw 22 perempuan dibunuh pacarnya ra alias alung 20 bogor pelaku dihukum berat ayah korban iwan irawan terima alung dihukum 15 tahun penjara sesuai pasal 338 kuhp pembunuhan iwan berharap alung dihukum seberat beratnya penjara seumur hidup baca wanita dibunuh pacarnya bogor mulutnya dibekap hidungnya digigit kepolisian hukum seberat beratnya seadil adilnya nyawa anak keberatan 15 tahun harapannya seumur hidup iwan ditemui mapolresta bogor kota selasa 5 12 2023 iwan menyangka kekasih anaknya pelaku pembunuh darah dagingnya hubungan asmara terjalin tahun setahun kenal dianggap anak main rumah iwan timbal baliknya bohong anak meninggal jatuh motor dibunuh sambung baca bekap pacar tewas bogor pelaku niat membunuhsejak peristiwa tragis iwan keluarga tersangka iktikad pemakaman anaknya keluarga tersangka keluarga tersangka iktikad baiknya ga komunikasinya iwan nyawa aja pertemuan pemakaman sambung\", \n",
    "#             \"calon presiden bacapres ganjar pranowo mengawali aktivitasnya berlari seputaran kota bandung jawa barat pria berambut putih menyusuri gang gang pemukiman warga\"]\n",
    "\n",
    "# # Extract model, vectorizer, and label encoder from loaded data\n",
    "# loaded_model = loaded_model_data['model']\n",
    "# loaded_vectorizer = loaded_model_data['vectorizer']\n",
    "# loaded_label_encoder = loaded_model_data['label_encoder']\n",
    "\n",
    "# # Vectorize the new data using the loaded CountVectorizer\n",
    "# new_data_features = loaded_vectorizer.transform(new_data)\n",
    "\n",
    "# # Predict sentiment using the loaded model\n",
    "# predictions = loaded_model.predict(new_data_features)\n",
    "\n",
    "# # Decode numerical labels back to text labels using the loaded LabelEncoder\n",
    "# predicted_sentiments = loaded_label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# # Print the predicted sentiments\n",
    "# for text, sentiment in zip(new_data, predicted_sentiments):\n",
    "#     print(f\"Text: '{text}' -> Predicted Sentiment: '{sentiment}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
