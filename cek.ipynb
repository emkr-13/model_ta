{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import concurrent.futures\n",
    "import time\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text=f\"\"\"Account Director of Integrated Account Department PT Huawei Tech Investment, Mukti Ali, akan diperiksa sebagai terdakwa kasus dugaan korupsi proyek BTS 4G Kominfo. Pemeriksaan akan dilakukan pada Senin, 23 Oktober 2023.\"Agenda sidang kita berikutnya di hari Senin, tanggal 23 Oktober 2023. Setelah saksi dilanjutkan pemeriksaan terdakwa ya,\" kata ketua hakim Dennie Arsan Fatrika dalam persidangan di PN Tipikor Jakarta, Jalan Bungur Besar Raya, Jakarta Pusat, Jumat (20/10/2023).Dennie mengatakan Mukti Ali juga akan diperiksa sebagai saksi mahkota terlebih dahulu. Kemudian dilanjutkan dengan pemeriksaan sebagai terdakwa.\"Demikian ya, jadi untuk persidangan berikutnya ditunda sampai dengan hari Senin, tanggal 23 Oktober 2023 ya dengan agenda untuk pemeriksaan saksi, masing-masing terdakwa sebagai saksi untuk perkara terdakwa lainnya dan dilanjutkan pemeriksaan terdakwa,\" ujarnya.Komisaris PT Solitech Media Sinergy Irwan Hermawan didakwa melakukan korupsi dalam proyek pengadaan base transceiver station (BTS) 4G dan infrastruktur pendukung paket 1, 2, 3, 4, dan 5 Bakti Kementerian Komunikasi dan Informatika tahun 2020-2022. Irwan didakwa merugikan negara Rp 8 triliun.Irwan diadili bersama Account Director of Integrated Account Department PT Huawei Tech Investment Mukti Ali dan Direktur Utama PT Mora Telematika Indonesia Galumbang Menak Simanjuntak. Mereka didakwa dalam berkas terpisah.Dalam dakwaan yang dibacakan jaksa dalam sidang di Pengadilan Tipikor Jakarta Pusat, Selasa (4/7/2023), Irwan beserta Tenaga Ahli Human Development Universitas Indonesia Tahun 2020 Yohan Suryanto, Direktur Utama Bakti Kominfo Anang Achmad Latif dan Galumbang serta Mukti melakukan pertemuan-pertemuan dengan calon kontraktor dan subkontraktor dalam rangka menentukan pelaksana pekerjaan. Pertemuan itu mengatur persyaratan pemilihan penyedia.Kemudian Irwan menentukan pemenang penyedia, yakni Konsorsium Fiber Home PT Telkominfra dan PT Multi Trans Data (PT MTD) untuk Paket 1, 2, lalu Konsorsium PT Lintas Arta, PT Huawei, dan PT Surya Energy Indotama (SEI) untuk Paket 3, serta Konsorsium PT Infra Struktur Bisnis Sejahtera (IBS) dan PT ZTE Indonesia Paket 4, 5.\"Anang Achmad Latif memerintahkan Ferandi Mirza untuk membentuk tim bayangan, yang terdiri dari Gandi, Avrinson, Maryulis, Edy untuk memastikan Pokja melaksanakan kriteria yang sudah ditentukan Anang Achmad Latif bersama-sama dengan Terdakwa Irwan Hermawan dan Galumbang Menak Simanjuntak,\" lanjut jaksa.Simak Video 'Sesal Johnny G Plate Proyek BTS Tak Selesai, Tapi Tak Merasa Salah':[Gambas:Video 20detik]Baca halaman selanjutnya>>Halaman 1 2 Selanjutnya bts kominfo kasus bts kominfo kasus korupsi bts kominfo korupsi bts kominfo hukum\"\"\"\n",
    "# content_cleaned = re.sub(r'ADVERTISEMENT', '', text)\n",
    "# content_cleaned = re.sub(r'Detik News', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'CNN News', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'KOMPAS.com', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'Kompas News', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'Gambas', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'20detik', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'berikutnya', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'halaman', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'detikcom', '', content_cleaned)\n",
    "# content_cleaned = re.sub(r'Halaman', '', content_cleaned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli: Aku mengakui Kesalahan Pemilu Sebagai Ketum Umum\n",
      "Hasil stemming: aku aku salah pemilu sebaga ketum umum\n"
     ]
    }
   ],
   "source": [
    "def stem(word):\n",
    "    # Daftar aturan awalan dan akhiran yang akan dihapus\n",
    "    awalan = [\"meng\", \"meny\", \"men\", \"mem\", \"me\", \"peng\", \"peny\", \"pen\", \"pem\", \"di\", \"ter\", \"ke\", \"ber\", \"per\"]\n",
    "    akhiran = [\"kan\", \"an\", \"i\"]\n",
    "\n",
    "    # Daftar kata-kata pengecualian (singkatan atau istilah khusus)\n",
    "    pengecualian = [\"indonesia\", \"pemilu\",\"ketum\"]\n",
    "\n",
    "    # Jika kata adalah kata pengecualian, kembalikan kata tanpa stemming\n",
    "    if word in pengecualian:\n",
    "        return word\n",
    "\n",
    "\n",
    "    # Hapus awalan\n",
    "    for awl in awalan:\n",
    "        if word.startswith(awl):\n",
    "            word = word[len(awl):]\n",
    "            break\n",
    "\n",
    "    # Hapus akhiran\n",
    "    for akh in akhiran:\n",
    "        if word.endswith(akh):\n",
    "            word = word[:-len(akh)]\n",
    "            break\n",
    "\n",
    "    # Exception: ubah 'perekonomian' menjadi 'ekonomi'\n",
    "    if word == 'perekonomian':\n",
    "        word = 'ekonomi'\n",
    "    elif word == 'mengakui':\n",
    "        word = 'akui'\n",
    "\n",
    "    return word\n",
    "\n",
    "# Contoh kalimat yang akan di-stem\n",
    "kalimat = \"Aku mengakui Kesalahan Pemilu Sebagai Ketum Umum\"\n",
    "\n",
    "content_cleaned  = kalimat.lower()\n",
    "\n",
    "# Tokenisasi kalimat menjadi kata-kata\n",
    "kata_kata = content_cleaned.split()\n",
    "\n",
    "# Lakukan stemming pada setiap kata\n",
    "hasil_stemming = [stem(kata) for kata in kata_kata]\n",
    "\n",
    "# Gabungkan kata-kata yang telah di-stem kembali menjadi kalimat\n",
    "kalimat_stem = ' '.join(hasil_stemming)\n",
    "\n",
    "# Tampilkan hasil stemming\n",
    "print(\"Kalimat asli:\", kalimat)\n",
    "print(\"Hasil stemming:\", kalimat_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat asli: Aku mengakui Kesalahan Pemilu Sebagai Ketum Umum\n",
      "Hasil stemming: Aku aku Kesalah Pemilu Sebaga Ketum Umum\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stem(word):\n",
    "    # Daftar aturan awalan dan akhiran yang akan dihapus\n",
    "    awalan = [\"meng\", \"meny\", \"men\", \"mem\", \"me\", \"peng\", \"peny\", \"pen\", \"pem\", \"di\", \"ter\", \"ke\", \"ber\", \"per\"]\n",
    "    akhiran = [\"kan\", \"an\", \"i\"]\n",
    "\n",
    "    # Daftar kata-kata pengecualian (singkatan atau istilah khusus)\n",
    "    pengecualian = [\"indonesia\", \"pemilu\", \"ketum\"]\n",
    "\n",
    "    # Jika kata adalah kata pengecualian, kembalikan kata tanpa stemming\n",
    "    if word.lower() in pengecualian:\n",
    "        return word\n",
    "\n",
    "    # Hapus awalan\n",
    "    for awl in awalan:\n",
    "        if word.startswith(awl):\n",
    "            word = word[len(awl):]\n",
    "            break\n",
    "\n",
    "    # Hapus akhiran\n",
    "    for akh in akhiran:\n",
    "        if word.endswith(akh):\n",
    "            word = word[:-len(akh)]\n",
    "            break\n",
    "\n",
    "    # Exception: ubah 'mengakui' menjadi 'akui'\n",
    "    if word == 'mengakui':\n",
    "        word = 'akui'\n",
    "\n",
    "    return word\n",
    "\n",
    "# Contoh kalimat yang akan di-stem\n",
    "kalimat = \"Aku mengakui Kesalahan Pemilu Sebagai Ketum Umum\"\n",
    "\n",
    "# Tokenisasi kalimat menggunakan NLTK\n",
    "kata_kata = word_tokenize(kalimat)\n",
    "\n",
    "# Lakukan stemming pada setiap kata\n",
    "hasil_stemming = [stem(kata) for kata in kata_kata]\n",
    "\n",
    "# Gabungkan kata-kata yang telah di-stem kembali menjadi kalimat\n",
    "kalimat_stem = ' '.join(hasil_stemming)\n",
    "\n",
    "# Tampilkan hasil stemming\n",
    "print(\"Kalimat asli:\", kalimat)\n",
    "print(\"Hasil stemming:\", kalimat_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kemudi\n",
      "ajar\n",
      "lepas\n",
      "bayang\n",
      "aku aku salah milu sebagai tum umum\n"
     ]
    }
   ],
   "source": [
    "from mpstemmer import MPStemmer\n",
    "\n",
    "stemmer = MPStemmer()\n",
    "\n",
    "print(stemmer.stem('mengemudi')) # => kemudi\n",
    "print(stemmer.stem('belajar')) # => ajar\n",
    "print(stemmer.stem('ngelepas')) # => lepas\n",
    "print(stemmer.stem('kebayang')) # => bayang\n",
    "\n",
    "print(stemmer.stem_kalimat('aku mengakui kesalahan pemilu sebagai ketum umum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model missing, downloading new model....\n",
      "\n",
      "Downloading Model 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DJ_u_xKSXmgS_CsM0xlB5rIznnDVfz-w\n",
      "To: /home/krisna/ProjectTA/model_ta/env/lib/python3.11/site-packages/NDETCStemmer/Model/w2vec_wiki_id_case\n",
      "100%|██████████| 26.7M/26.7M [00:07<00:00, 3.72MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading Model 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1DQhPp-D3o0e-x3PfJd2Il3vf7wVgZu4J\n",
      "From (redirected): https://drive.google.com/uc?id=1DQhPp-D3o0e-x3PfJd2Il3vf7wVgZu4J&confirm=t&uuid=23fbe85f-917a-42a9-85a6-5a1b8b6ef11b\n",
      "To: /home/krisna/ProjectTA/model_ta/env/lib/python3.11/site-packages/NDETCStemmer/Model/w2vec_wiki_id_case.trainables.syn1neg.npy\n",
      "100%|██████████| 328M/328M [01:25<00:00, 3.84MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading Model 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zCn5YINEC82cZ1SH-nB4WXUvuELCzKu-\n",
      "From (redirected): https://drive.google.com/uc?id=1zCn5YINEC82cZ1SH-nB4WXUvuELCzKu-&confirm=t&uuid=16230b4f-5bdd-4416-8a2a-d4b86d9d6953\n",
      "To: /home/krisna/ProjectTA/model_ta/env/lib/python3.11/site-packages/NDETCStemmer/Model/w2vec_wiki_id_case.wv.vectors.npy\n",
      "100%|██████████| 328M/328M [01:23<00:00, 3.92MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download Complete\n",
      "boleh saya perah lembu ini \n",
      "aku aku salah milu bagai tum umum \n"
     ]
    }
   ],
   "source": [
    "#import NDETCStemmer library\n",
    "from NDETCStemmer import NDETCStemmer\n",
    "\n",
    "#init stemmer\n",
    "stemmer=NDETCStemmer()\n",
    "\n",
    "# stemming process\n",
    "output=stemmer.stem('boleh saya memerah lembu ini')\n",
    "\n",
    "print(output)\n",
    "#boleh saya perah lembu ini\n",
    "\n",
    "print(stemmer.stem('aku mengakui kesalahan pemilu sebagai ketum umum'))\n",
    "#bibir merah tangan jadi lengket madu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
